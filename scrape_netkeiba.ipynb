{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNgzbldKCLClUewH7hcpLi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nd82914/KeibaProject/blob/master/scrape_netkeiba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7HvKb7hStTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \"\"\"\n",
        "  !apt-get update\n",
        "  !apt install chromium-chromedriver\n",
        "  !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "  !pip install selenium\n",
        "  \"\"\"\n",
        "  from selenium import webdriver\n",
        "  from selenium.webdriver.chrome.options import Options\n",
        "  from urllib.parse import urljoin\n",
        "  from bs4 import BeautifulSoup\n",
        "  from google.colab import files\n",
        "  import re\n",
        "  import csv\n",
        "  import pandas as pd\n",
        "  from datetime import datetime\n",
        "  from datetime import datetime as dt\n",
        "  from datetime import timedelta\n",
        "  global url_date\n",
        "\n",
        "  def Read_Initxt():\n",
        "      # ini.txtファイルからスクレイピングの対象をdict化する\n",
        "      #files.upload()\n",
        "      #ini_path = \"C:/Envs/test/ini.txt\"    # ini ファイルのみソース内で指定が必要。フルパスがよい。\n",
        "      try:    # ファイルが開けなかったらエラーになるので、try~except 文を使いましょう。\n",
        "          with open(\"ini_4.txt\", 'r') as ini:\n",
        "          #print(ini.read())\n",
        "          #ini = open(ini_path, \"r\")    # txtファイルを読み取りモード（”ｒ”）で開く　\n",
        "            ini_line = ini.readlines()    # txt内容を1行ずつ区切って配列にするメソッド\n",
        "            ini_data = {}     # この空のdictの中にデータを詰めていきます\n",
        "          for line in ini_line:\n",
        "              line = line.rstrip(\"\\n\") # 改行コードを取り除く\n",
        "              line = line.split(\" \") # iniファイル内は\" \"で分けているので、それぞれの要素に分けて配列にする\n",
        "              for i in range(1,len(line)): #index[0]はdictのkeyになる\n",
        "                  if i == 1 : \n",
        "                      ini_data[line[0]] = []# {\"key\" : [\"value1\", \"value2\"...]}の形にする\n",
        "                  if line[i] != \"\" and line[i][0] != \"#\":\n",
        "                      ini_data[line[0]].append(line[i])\n",
        "          ini.close()\n",
        "          #print(ini_data)\n",
        "      except:\n",
        "          print(\"There is no initial files.\")\n",
        "          exit() #ini.txtが読み込めないとこちらに入ってメッセージを出力してプログラムを終了\n",
        "      return(ini_data)\n",
        "\n",
        "  def Output(out):\n",
        "      with open(\"KeibaData\", \"w\", encoding='utf-8') as data:\n",
        "      #  data.write(\"【出力内容】\")\n",
        "      #data = open(ini_data[\"out_path\"][0], \"a\", encoding='utf-8')    # 今度は追記モード(\"a\")で開きます。ファイルがなければ作成されます。\n",
        "          writer = csv.writer(data)\n",
        "\n",
        "          writer.writerow(out)    # データの書込み\n",
        "          data.close()    # 開けたファイルは最後に閉めましょう\n",
        "          #files.download(\"KeibaData\")\n",
        "\n",
        "  def MakeHeadTable(source):\n",
        "      \"\"\"\n",
        "      in=nettokeibaのソース\n",
        "      out=th, td\n",
        "      thは以下のリスト['レースID', 'レース番号','レース名','障害','左・右','内・外','距離[m]','天候','芝・ダ：状態','発走時刻','年月','開催場所','レースクラス','その他']\n",
        "      tdはそのデータ\n",
        "      \"\"\"\n",
        "      raceID=raceNo=raceName=None\n",
        "      ditail=[None,None,None,None]\n",
        "      condition=[None,None,None,None]\n",
        "      raceDate=[None,None,None,None]\n",
        "\n",
        "      data_intro = source.find(\"div\", class_=\"data_intro\")#属性がclassの場合class_と表記することに注意\n",
        "      raceNo=data_intro.find(\"dt\").get_text().replace(' ','').replace('\\n','')\n",
        "      raceName=data_intro.find(\"h1\").get_text()\n",
        "      condition=data_intro.find(\"span\").get_text().replace(' ','').replace('\\xa0\\xa0',',').replace('\\xa0/\\xa0',' ').split()\n",
        "      raceDate=data_intro.find(\"p\", class_=\"smalltxt\").get_text().split()\n",
        "      #2020年3月29日 2回阪神2日目 3歳未勝利  [指](馬齢)　空白で分割しリスト化　4個以上なら4個になるまで[-1] を[-2]に結合\n",
        "      if len(raceDate) < 4:\n",
        "          print(\"Error:レース情報が足りません\")\n",
        "          exit\n",
        "      elif len(raceDate)>4:\n",
        "          print(\"Error:情報過多です。超過分をして出力します\")\n",
        "          while len(raceDate) > 4:\n",
        "              raceDate[-2]=raceDate[-2]+raceDate[-1]\n",
        "              del raceDate[-1]\n",
        "      #['障害','右左','外内','距離']\n",
        "      isSyougai = ('障' in condition[0])\n",
        "      RightLeft = ('右' if '右' in condition[0] else '左' if '左' in condition[0] else False)\n",
        "      OutIn = ('外' if '外' in condition[0] else '内' if '内' in condition[0] else False)\n",
        "      distance=re.search(r'\\d{3,}', condition[0]).group()#三桁以上の数字列を正規表現で抜き出す\n",
        "      ditail=[isSyougai, RightLeft, OutIn, distance]\n",
        "\n",
        "      csvRow=[]\n",
        "      raceID=url_date\n",
        "      csvRow.append(raceID)\n",
        "      csvRow.append(raceNo)\n",
        "      csvRow.append(raceName)\n",
        "      csvRow.extend(ditail)\n",
        "      csvRow.extend(condition[1:])\n",
        "      csvRow.extend(raceDate)\n",
        "      #print(csvRow)\n",
        "      #ラップタイム,ペース追加\n",
        "      raceRap=racePace=None\n",
        "      RapPaceList=(raceRap,racePace)\n",
        "      try:\n",
        "          table_rap_pace = source.find(\"table\",summary=\"ラップタイム\")\n",
        "          data_rap_pace=table_rap_pace.find_all(\"td\")\n",
        "          raceRap=data_rap_pace[0].get_text().replace(\" \",\"\").replace(\"\\xa0\",\"\")\n",
        "          racePace=data_rap_pace[1].get_text().replace(\" \",\"\").replace(\"\\xa0\",\"\")\n",
        "      except:\n",
        "          pass\n",
        "      csvRow.append(raceRap)\n",
        "      csvRow.append(racePace)\n",
        "      th=['レースID', 'レース番号','レース名','障害','左・右','内・外','距離[m]','天候','芝・ダ：状態','発走時刻','年月','開催場所','レースクラス','その他','ラップタイム','ペース']\n",
        "\n",
        "      if len(csvRow) != len(th):\n",
        "          print(\"Error:データタイトル数とデータ数が合いません\")\n",
        "          exit()\n",
        "      else:\n",
        "          pass\n",
        "      return(th,csvRow)\n",
        "  \"\"\"\n",
        "  def MakePosThTd(source):\n",
        "      \n",
        "      #in=nettokeibaのソース\n",
        "      #out=th, td\n",
        "      #thは以下のリスト['単勝No','単勝Odds','単勝Fav','複勝','複勝','複勝','枠連','枠連','枠連','年月','開催場所','レースクラス','その他']\n",
        "      #tdはそのデータ\n",
        "      \n",
        "      th_sort=[\"単勝\",\"複勝1\",\"複勝2\",\"複勝3\",\"枠連\",\"馬連\",\"ワイド1\",\"ワイド2ワイド3馬単三連複三連単]\n",
        "      return(th,td)\n",
        "      \"\"\"\n",
        "\n",
        "  def MakeHeadTable2(source):\n",
        "      data_race_header = source.find(\"div\",class_=\"Race_header\")\n",
        "      #raceNo取得\n",
        "      try:\n",
        "          raceDate=data_race_header.find(\"span\",class_=\"Race_Date\").get_text().replace(\"\\n\",\"\")\n",
        "      except:\n",
        "          raceDate=None\n",
        "      header_No_Place = []\n",
        "      try:#raceNo,racePlace取得\n",
        "          for header_tmp in data_race_header.find_all(\"option\"):\n",
        "              if \"url_date\" in header_tmp[\"value\"]:#optionタグのリスト内に一致文字列があれば取り出す\n",
        "                  header_No_Place.append(header_tmp.get_text())\n",
        "          racePlace=header_No_Place[0]\n",
        "          raceNo=header_No_Place[1]\n",
        "      except:\n",
        "          raceNo=None\n",
        "          racePlace=None\n",
        "\n",
        "      data_intro = source.find(\"div\", class_=\"RaceHeader_Value\")#属性がclassの場合class_と表記することに注意\n",
        "      data_intro2 = data_intro.find_all(\"span\")\n",
        "      print(data_intro2)\n",
        "      deleteNo=0\n",
        "      raceName=raceTime=raceDitail=raceWhether=raceCondition=raceClass=raceEtc=None\n",
        "      for introdata in data_intro2:\n",
        "          print(introdata)\n",
        "          try:\n",
        "              if introdata[\"class\"] == [\"RaceName_main\"]:\n",
        "                  raceName = introdata.get_text()\n",
        "          except:\n",
        "              pass\n",
        "          try:\n",
        "              if \"発走\" in introdata.get_text():\n",
        "                  raceTime = introdata.get_text()\n",
        "          except:\n",
        "              pass\n",
        "          try:\n",
        "              if introdata[\"class\"] == [\"Turf\"]:\n",
        "                  raceDitail = introdata.get_text()\n",
        "          except:\n",
        "              pass\n",
        "          try:\n",
        "              if introdata[\"class\"] == [\"WeatherData\"]:\n",
        "                  raceWhether = introdata.get_text()\n",
        "          except:\n",
        "              pass\n",
        "\n",
        "      print(raceName,raceTime)\n",
        "\n",
        "          \n",
        "      try:\n",
        "          raceTime=data_intro2[1].get_text()\n",
        "      except:\n",
        "          raceTime=None\n",
        "          #print(\"raceTime=None\")\n",
        "      try:\n",
        "          raceDitail=data_intro2[2].get_text()\n",
        "      except:\n",
        "          raceDitail=None\n",
        "      try:\n",
        "          raceWhether=data_intro2[3].get_text()\n",
        "      except:\n",
        "          raceWhether=None\n",
        "      try:\n",
        "          raceCondition=data_intro2[5].get_text()\n",
        "      except:\n",
        "          raceCondition=None\n",
        "      try:\n",
        "          raceClass=data_intro2[6].get_text()\n",
        "      except:\n",
        "          raceClass=None\n",
        "      try:\n",
        "          raceEtc=data_intro2[7].get_text()\n",
        "      except:\n",
        "          raceEtc=None\n",
        "\n",
        "      #['障害','右左','外内','距離']\n",
        "      isSyougai = ('障' in raceDitail)\n",
        "      RightLeft = ('右' if '右' in raceDitail else '左' if '左' in raceDitail else None)\n",
        "      OutIn = ('外' if '外' in raceDitail else '内' if '内' in raceDitail else None)\n",
        "      distance=re.search(r'\\d{3,}', raceDitail).group()#三桁以上の数字列を正規表現で抜き出す\n",
        "      if '芝' in raceDitail and 'ダ' not in raceDitail:\n",
        "          ShibaDa = '芝'\n",
        "      elif 'ダ' in raceDitail and '芝' not in raceDitail:\n",
        "          ShibaDa = 'ダ'\n",
        "      elif '芝' in raceDitail and 'ダ' in raceDitail:\n",
        "          ShibaDa = '芝・ダ'\n",
        "      else:\n",
        "          ShibaDa = None  \n",
        "      ditail_list=[isSyougai, RightLeft, OutIn, distance, ShibaDa]\n",
        "\n",
        "      td=[]\n",
        "      td.append(raceNo)\n",
        "      td.append(raceName)\n",
        "      td.append(racePlace)\n",
        "      td.extend(ditail_list)\n",
        "      td.append(raceWhether)\n",
        "      td.append(raceTime)\n",
        "      td.append(raceCondition)\n",
        "      td.append(raceDate)\n",
        "      td.append(raceClass)\n",
        "      td.append(raceEtc)\n",
        "      th=['レース番号','レース名','場所','障害','左・右','内・外','距離[m]','芝・ダ','天候','発走時刻','馬場状態','年月','開催場所レースクラス','その他']\n",
        "      if len(td) != len(th):\n",
        "          print(\"Error:データタイトル数とデータ数が合いません\")\n",
        "          exit()\n",
        "      return(th,td)\n",
        "  def OutputHeadTable(th,td):\n",
        "      print(\"--------------------------------headtable--------------------------------\")\n",
        "      print(th)\n",
        "      print(td)\n",
        "      data_name=url_date.replace(\"/\",\"_\")\n",
        "      with open(\"HeadData%s.csv\"%data_name, \"w\", encoding='utf-8') as data:\n",
        "          writer = csv.writer(data)\n",
        "          writer.writerow(th)\n",
        "          writer.writerow(td)\n",
        "      data.close()\n",
        "      files.download(\"HeadData%s.csv\"%data_name)\n",
        "      print(\"--------------------------------headtable--------------------------------\")\n",
        "      !rm *.csv\n",
        "\n",
        "  def OutputTable(Table_Souce):\n",
        "\n",
        "      print(\"--------------------------------outputtable--------------------------------\")\n",
        "      rows = Table_Souce.find_all(\"tr\")\n",
        "      data_name=url_date.replace(\"/\",\"_\")\n",
        "      with open(\"RaceData%s.csv\"%data_name, \"w\", encoding='utf-8') as data:\n",
        "          writer = csv.writer(data)\n",
        "          i=0\n",
        "          for row in rows:\n",
        "              csvRow = []\n",
        "              for cell in row.find_all(['td', 'th']):\n",
        "                  #print(cell)\n",
        "                  csvRow.append(cell.get_text().replace('\\n',''))\n",
        "              if i==0:\n",
        "                csvRow=[\"レースID\"] + csvRow\n",
        "              else:\n",
        "                csvRow=[url_date] + csvRow\n",
        "              writer.writerow(csvRow)\n",
        "              i+=1\n",
        "              print(csvRow)\n",
        "      data.close()\n",
        "      files.download(\"RaceData%s.csv\"%data_name)\n",
        "      print(\"--------------------------------outputtable--------------------------------\")\n",
        "      !rm *.csv\n",
        "\n",
        "  def pandalize(Table_Souce,preth,pretd):\n",
        "      rows = Table_Souce.find_all(\"tr\")\n",
        "      i=0\n",
        "      lists=[]\n",
        "      for row in rows:\n",
        "          csvRow = []\n",
        "          for cell in row.find_all(['td', 'th']):\n",
        "              #print(cell)\n",
        "              csvRow.append(cell.get_text().replace('\\n',''))\n",
        "          if i==0:\n",
        "            csvRow=preth + csvRow\n",
        "            columns=csvRow\n",
        "          else:\n",
        "              csvRow=pretd + csvRow\n",
        "              lists.append(csvRow)\n",
        "          i+=1\n",
        "      df = pd.DataFrame(data=lists,columns=columns)\n",
        "      print(df.head())\n",
        "\n",
        "  def Print_Soup():\n",
        "      options = webdriver.ChromeOptions()\n",
        "      options.add_argument('--headless')\n",
        "      options.add_argument('--no-sandbox')\n",
        "      options.add_argument('--disable-dev-shm-usage')\n",
        "      driver = webdriver.Chrome('chromedriver',options=options)\n",
        "      driver.implicitly_wait(10)\n",
        "      driver.get(\"https://www.netkeiba.com/\")\n",
        "      html = driver.page_source.encode('utf-8')\n",
        "      soup = BeautifulSoup(html, \"html.parser\")\n",
        "      print(soup.prettify())\n",
        "\n",
        "\n",
        "  def Soup(url_link):\n",
        "      #ini_data=Read_Initxt()\n",
        "      #print(ini_data)\n",
        "      # webサイトからデータを取得して、出力\n",
        "      #try:\n",
        "      result = []    # 書き込む内容を配列にする\n",
        "      result.append(datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))#　出力する時間を取得する\n",
        "      # ブラウザのオプションを格納する変数をもらってきます。ブラウザをバックグラウンド起動するかなどを指定\n",
        "      webdriver.ChromeOptions()\n",
        "      #options = dr.chrome.options.Options()\n",
        "      # options = dr.firefox.options.Options()    # Firefoxで行いたい場合はこちらを使います\n",
        "      #options.set_headless(False)    # Trueにすると、バックグラウンド起動になります。\n",
        "      options = webdriver.ChromeOptions()\n",
        "      options.add_argument('--headless')\n",
        "      options.add_argument('--no-sandbox')\n",
        "      options.add_argument('--disable-dev-shm-usage')\n",
        "      \n",
        "      # ブラウザを起動する\n",
        "      #driver = dr.Chrome(executable_path=ini_data[\"driver_path\"][0], chrome_options=options) # webdriver を立ち上げる\n",
        "      driver = webdriver.Chrome('chromedriver',options=options)\n",
        "      #driver.implicitly_wait(10)\n",
        "      # driver = dr.Firefox(executable_path=ini_data[\"driver_path\"][0], firefox_options=options) # Firefoxで行いたい場合はこちらを使います\n",
        "      #link = ini_data[\"link\"][0]\n",
        "      link=url_link\n",
        "      driver.get(link)# 指定したリンクのページにアクセスする\n",
        "      html = driver.page_source.encode('utf-8')# アクセスしたページのhtmlソースを取得\n",
        "      source = BeautifulSoup(html, \"html.parser\") # htmlソースの解析、lxmlではなぜか動かない\n",
        "      th,td=MakeHeadTable(source)\n",
        "      OutputHeadTable(th,td)\n",
        "      OutputTable(source.find(\"table\"))\n",
        "      #pandalize(table[0],th,td)\n",
        "\n",
        "      driver.close()\n",
        "\n",
        "  def IterateDates():\n",
        "      datelist = []\n",
        "      dates=[]\n",
        "      strdt = dt.strptime(\"20150401\", '%Y%m%d')  # 開始日\n",
        "      enddt = dt.strptime(\"20181219\", '%Y%m%d')  # 終了日\n",
        "\n",
        "      # 日付差の日数を算出（リストに最終日も含めたいので、＋１しています）\n",
        "      days_num = (enddt - strdt).days + 1  # （参考）括弧の部分はtimedelta型のオブジェクトになります\n",
        "      for i in range(days_num-1,-1,-1):\n",
        "          datelist.append(strdt+timedelta(days=i))\n",
        "      for date in datelist:\n",
        "          dates.append(date.strftime('%Y%m%d'))\n",
        "          #print(date.strftime('%Y%m%d'))\n",
        "      print(\"開始日:%s\"%strdt,\"終了日:%s\"%enddt,\"日数:%d\"%days_num)\n",
        "      #print(dates)\n",
        "      return(dates)\n",
        "\n",
        "  def IterationScraping():\n",
        "      global url_date #グローバル変数を関数内で変更するときは宣言が必要\n",
        "\n",
        "      webdriver.ChromeOptions()\n",
        "      options = webdriver.ChromeOptions()\n",
        "      options.add_argument('--headless')\n",
        "      options.add_argument('--no-sandbox')\n",
        "      options.add_argument('--disable-dev-shm-usage')\n",
        "      \n",
        "      # ブラウザを起動する\n",
        "      driver = webdriver.Chrome('chromedriver',options=options)\n",
        "      driver.implicitly_wait(5)\n",
        "      # driver = dr.Firefox(executable_path=ini_data[\"driver_path\"][0], firefox_options=options) # Firefoxで行いたい場合はこちらを使います\n",
        "      #link = ini_data[\"link\"][0]\n",
        "      for date in IterateDates():\n",
        "          link=\"https://db.netkeiba.com/race/list/%s/\"%date\n",
        "          print(\"access to link:%s\"%link)\n",
        "          driver.get(link)# 指定したリンクのページにアクセスする\n",
        "          html = driver.page_source.encode('utf-8')# アクセスしたページのhtmlソースを取得\n",
        "          source = BeautifulSoup(html, \"html.parser\") # htmlソースの解析、lxmlではなぜか動かない\n",
        "          data_lists = source.find_all(\"div\", class_=\"race_list fc\")#属性がclassの場合class_と表記することに注\n",
        "          if len(data_lists) == 0:\n",
        "              print(\"%s:開催したレースがありません\"%date)\n",
        "              #driver.close()\n",
        "              continue\n",
        "          else:\n",
        "              pass\n",
        "          data_lists2 = source.find_all(\"a\",href=re.compile(\"/race/\\d+\"))\n",
        "          print(\"%s:開催レース数%d\"%(date,len(data_lists)))\n",
        "          for datalist in data_lists2:\n",
        "              db_url=urljoin(\"https://db.netkeiba.com/\",datalist.get(\"href\"))\n",
        "              url_date=datalist.get(\"href\")#/race/202006030203/のような文字列をグローバル変数に代入\n",
        "              print(\"URL:%s\"%db_url)\n",
        "              Soup(db_url)\n",
        "      driver.close()\n",
        "\n",
        "\n",
        "  #url_date=\"/race/201908040608/\"\n",
        "  #Soup(\"https://db.netkeiba.com/race/201908040608/\")\n",
        "  #Print_Soup()\n",
        "\n",
        "  IterationScraping()\n",
        "  #/race/202006030203/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrlQcu4rano2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  !apt-get update\n",
        "  !apt install chromium-chromedriver\n",
        "  !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "  !pip install selenium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn0i2iO9BDIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M_t5s4bK37W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"HeadData_race_201903020507_.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uf73lityhdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paTnDjXzn5rv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXwdQMTbl9Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}